<launch>

  <arg name="head_tracking_frame" default="camera"/>
  <arg name="device" default="/dev/video0"/>
  <arg name="calibration" default=""/>

  <!-- Open the webcam, and stream it (to the topic /camera/image_raw) -->
  <node name="webcam_source" pkg="gscam" type="gscam" output="screen">
    <param name="camera_name" value="default"/>
    <param name="camera_info_url" value="$(arg calibration)"/>
    <param name="gscam_config" value="v4l2src device=$(arg device) ! video/x-raw-yuv,width=640,height=360 ! ffmpegcolorspace"/>
    <param name="frame_id" value="$(arg head_tracking_frame)"/>
    <param name="sync_sink" value="true"/>
  </node>

  <node name="camera_transform" pkg="tf" type="static_transform_publisher" args="0.1 0 0 1.57 0 1. /base_link $(arg head_tracking_frame) 100"/>

  <node pkg="attention_assessment" type="head_pose_estimator" name="head_pose_estimator" output="screen">
    <param name="face_model" value="$(find attention_assessment)/shape_predictor_68_face_landmarks.dat" />
    <param name="camera_frame" value="$(arg head_tracking_frame)" />
    <remap from="/image" to="/camera/image_raw"/>
  </node>

  <node pkg="attention_assessment" type="current_focus.py" name="current_focus" output="screen" />

</launch>
